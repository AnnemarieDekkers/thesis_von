{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5vC24K6pG9j"
      },
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQtCZkLxrNMP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, r2_score,\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, confusion_matrix\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from collections import deque\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Activation, Dropout, LSTM, GRU, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
        "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AufwtQ6uzbV-",
        "outputId": "3b0bf72a-0853-49bc-a7d7-b1fd2fd3d7be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "def read(file):\n",
        "    df = pd.read_csv(file, low_memory=False)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    return df\n",
        "\n",
        "\n",
        "def isp(df):\n",
        "  df[\"NL_DT\"]  = pd.to_datetime(df[\"NL_DT\"], format=\"%d/%m/%y %H:%M\")\n",
        "\n",
        "  if \"ISP\" not in df.columns:\n",
        "    df[\"ISP\"] = df.groupby(df[\"NL_DT\"].dt.date).cumcount() + 1\n",
        "  df[\"jaar\"] = df[\"NL_DT\"].dt.year\n",
        "  return df\n",
        "\n",
        "\n",
        "def drop(df):\n",
        "  df.drop(columns=['NL_DT'], inplace=True)\n",
        "\n",
        "  if 'kWh_APX_zon' in df.columns:\n",
        "    df.drop(columns=['kWh_APX_zon'], inplace=True)\n",
        "  return df\n",
        "\n",
        "\n",
        "def obj_float(df):\n",
        "  for col in df.columns:\n",
        "    df[col] = df[col].astype(str).str.replace('(', '').str.replace(')', '')\n",
        "    df[col] = df[col].astype(str).str.replace('-', '0')\n",
        "    df[col] = df[col].astype(str).str.replace(',', '.', regex=False)\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "  # NaNs filled with zeros\n",
        "  df.fillna(0, inplace=True)\n",
        "\n",
        "  df.sort_values(by=['jaar', 'maand', 'DagM', 'ISP'], inplace=True)\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "  return df\n",
        "\n",
        "\n",
        "def mwh_to_kwh(df, column):\n",
        "  df[column] = df[column] / 1000\n",
        "  return df\n",
        "\n",
        "\n",
        "def plot_loss(history, title='Loss per Epoch'):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(history.history['loss'], label='Training loss')\n",
        "    if 'val_loss' in history.history:\n",
        "        plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluate_model_results(model, model_name, X_train, X_test, y_train_idx, y_test_idx, duration, future, dataset):\n",
        "    df = pd.DataFrame(columns=['imbalance_price', 'predicted', 'test'])\n",
        "    df['imbalance_price'] = [row['Imbalance'] for row in dataset[duration+future:]]\n",
        "\n",
        "    # predictions\n",
        "    df.loc[y_train_idx, 'predicted'] = model.predict(X_train).flatten()\n",
        "    df.loc[y_test_idx, 'predicted'] = model.predict(X_test).flatten()\n",
        "    df.loc[y_train_idx, 'test'] = False\n",
        "    df.loc[y_test_idx, 'test'] = True\n",
        "\n",
        "    # for test/train results\n",
        "    df_test = df[df['test'] == True]\n",
        "    df_train = df[df['test'] == False]\n",
        "\n",
        "    y_true = df_test['imbalance_price'].values\n",
        "    y_pred = df_test['predicted'].values\n",
        "    y_train = df_train['imbalance_price'].values\n",
        "    y_pred_train = df_train['predicted'].values\n",
        "\n",
        "    # metrics\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "\n",
        "    mape = np.mean(np.abs((y_true[y_true != 0] - y_pred[y_true != 0]) / y_true[y_true != 0])) * 100\n",
        "    nrmse = rmse / np.mean(y_true)\n",
        "    nmae = mae / np.mean(y_true)\n",
        "\n",
        "    # results\n",
        "    print(f\"\\n Results for {model_name}\")\n",
        "    print(f\"------------------------\")\n",
        "    print(f\"R² Score:       {r2:.4f}\")\n",
        "    print(f\"MSE (test):     {mse:.4f}\")\n",
        "    print(f\"MSE (train):    {mse_train:.4f}\")\n",
        "    print(f\"MAE:            {mae:.4f}\")\n",
        "    print(f\"RMSE:           {rmse:.4f}\")\n",
        "    print(f\"MAPE:           {mape:.2f}%\")\n",
        "    print(f\"nRMSE (mean):   {nrmse:.4f}\")\n",
        "    print(f\"nMAE (mean):    {nmae:.4f}\")\n",
        "\n",
        "    # to see if there are peaks in the testdata:\n",
        "    threshold = 400\n",
        "    df_peaks = df_test.copy()\n",
        "\n",
        "    df_peaks[\"correct_pred\"] = df_peaks[\"imbalance_price\"] >= threshold & df_peaks[\"predicted\"] >= threshold\n",
        "\n",
        "    total = df_peaks[\"true_peak\"].sum()\n",
        "    correct = df_peaks[\"correct_pred\"].sum()\n",
        "\n",
        "    print(\"\\n Peak prediction:\")\n",
        "    print(f\"Total amount of peaks ≥ {threshold:.0f}: {total}\")\n",
        "    print(f\"Correct predicted: {correct}\")\n",
        "\n",
        "\n",
        "def evaluate_classification(model, model_name, X_train, X_test, y_train_idx, y_test_idx, duration, future, dataset, threshold=400):\n",
        "    df = pd.DataFrame(columns=['imbalance_price', 'predicted', 'test'])\n",
        "    df['imbalance_price'] = [row['Imbalance'] for row in dataset[duration+future:]]\n",
        "\n",
        "    # predictions\n",
        "    df.loc[y_train_idx, 'predicted'] = model.predict(X_train).flatten()\n",
        "    df.loc[y_test_idx, 'predicted'] = model.predict(X_test).flatten()\n",
        "    df.loc[y_train_idx, 'test'] = False\n",
        "    df.loc[y_test_idx, 'test'] = True\n",
        "\n",
        "    # only testset\n",
        "    df_test = df[df['test'] == True]\n",
        "\n",
        "    y_true = df_test['imbalance_price'].values\n",
        "    y_pred = df_test['predicted'].values\n",
        "\n",
        "    # convert to binary classes\n",
        "    y_true_peak = np.array([1 if abs(val) >= threshold else 0 for val in y_true])\n",
        "    y_pred_peak = np.array([1 if abs(val) >= threshold else 0 for val in y_pred])\n",
        "    print(\"y_true_peak:\", y_true_peak[:5])\n",
        "    print(\"y_pred_peak:\", y_pred_peak[:5])\n",
        "\n",
        "\n",
        "    # metrics\n",
        "    accuracy = accuracy_score(y_true_peak, y_pred_peak)\n",
        "    precision = precision_score(y_true_peak, y_pred_peak)\n",
        "    recall = recall_score(y_true_peak, y_pred_peak)\n",
        "    f1 = f1_score(y_true_peak, y_pred_peak)\n",
        "    cm = confusion_matrix(y_true_peak, y_pred_peak)\n",
        "\n",
        "    # results\n",
        "    print(f\"\\n Results for classification: {model_name}\")\n",
        "    print(\"----------------------------------------\")\n",
        "    print(f\"Accuracy:       {accuracy:.4f}\")\n",
        "    print(f\"Precision:      {precision:.4f}\")\n",
        "    print(f\"Recall:         {recall:.4f}\")\n",
        "    print(f\"F1 Score:       {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "def onbalans_data(file):\n",
        "  df = pd.read_csv(file, delimiter=';')\n",
        "  df.columns = df.columns.str.strip()\n",
        "\n",
        "  df['Timeinterval Start Loc'] = pd.to_datetime(df['Timeinterval Start Loc'])\n",
        "  df['maand'] = df['Timeinterval Start Loc'].dt.month\n",
        "  df['DagM'] = df['Timeinterval Start Loc'].dt.day\n",
        "  df['jaar'] = df['Timeinterval Start Loc'].dt.year\n",
        "\n",
        "  df.drop(columns=['Timeinterval Start Loc', 'Timeinterval End Loc', 'Quantity Measurement Unit'], inplace=True)\n",
        "  df.rename(columns={'Isp': 'ISP'}, inplace=True)\n",
        "\n",
        "  mwh_to_kwh(df, 'Surplus')\n",
        "  mwh_to_kwh(df, 'Shortage')\n",
        "  mwh_to_kwh(df, 'Absolute')\n",
        "  mwh_to_kwh(df, 'Imbalance')\n",
        "\n",
        "  # column indicating whether there is a peak in the Imbalance\n",
        "  threshold = 400\n",
        "  df['piek'] = df['Imbalance'].apply(lambda x: 1 if abs(x) >= threshold else 0)\n",
        "\n",
        "  return df\n",
        "\n",
        "# --- Load files --- #\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "file_path = '/content/drive/MyDrive/Thesis_VON'\n",
        "\n",
        "df_jan2021 = read(f'{file_path}/2021_jan-jun.csv')\n",
        "df_jul2021 = read(f'{file_path}/2021_jul-dec.csv')\n",
        "df_2022 = read(f'{file_path}/2022.csv')\n",
        "df_2023 = read(f'{file_path}/2023.csv')\n",
        "df_2024 = read(f'{file_path}/zonneproductie_2024.csv')\n",
        "\n",
        "\n",
        "# change the column names so they are the same (2021)\n",
        "df_jan2021.rename(columns={'kWh_real': 'kWh_real_zon', 'kWh_nom': 'kWh_nom_zon',\n",
        "                           'kWh_APX': 'kWh_APX_zon', 'kWh_shor': 'kWh_shor_zon',\n",
        "                           'kWh_sur': 'kWh_sur_zon', 'eur_APX': 'eur_APX_zon',\n",
        "                           'eur_sur': 'eur_sur_zon', 'eur_shor': 'eur_shor_zon',\n",
        "                           'eur_tot': 'eur_tot_zon'}, inplace=True)\n",
        "df_2023.rename(columns={'eur_short_zon': 'eur_shor_zon', 'p_short': 'p_shor',\n",
        "                        'eur_real_zon': 'eur_tot_zon'}, inplace=True)\n",
        "df_2024.rename(columns={'eur_short_zon': 'eur_shor_zon', 'p_short': 'p_shor',\n",
        "                        'eur_real_zon': 'eur_tot_zon'}, inplace=True)\n",
        "# remove the unnecessary columns\n",
        "df_jan2021.drop(columns=['kWh_Tele', 'kWh_prof', 'kWh_forward', 'kWh_imb',\n",
        "                         'EUR prof real', 'p_forward', 'eur_forward', 'NL_DT.1',\n",
        "                         'kWh_levering', 'kWh_terug', 'aantal_eans', 'kWh_APX_inkoop',\n",
        "                         'kWh_APX_verkoop', 'NL_DT.2', 'kWh_nom_zonnepark'], inplace=True)\n",
        "df_2022.drop(columns=['tijd'], inplace=True)\n",
        "df_2024.drop(columns=['Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21'], inplace=True)\n",
        "\n",
        "# make one dataset for 2021\n",
        "df_2021 = pd.concat([df_jan2021, df_jul2021])\n",
        "\n",
        "# add ISP + drop\n",
        "df_2021 = obj_float(drop(isp(df_2021)))\n",
        "df_2022 = obj_float(drop(isp(df_2022)))\n",
        "df_2023 = obj_float(drop(isp(df_2023)))\n",
        "\n",
        "# Special case: df_2024 (no NL_DT)\n",
        "df_2024 = drop(df_2024)\n",
        "df_2024[\"jaar\"] = 2024\n",
        "df_2024 = obj_float(df_2024)\n",
        "\n",
        "df_all = pd.concat([df_2021, df_2022, df_2023, df_2024], ignore_index=True)\n",
        "\n",
        "df_onbalans2021 = onbalans_data(f'{file_path}/settled_imbalance_2021.csv')\n",
        "df_onbalans2022 = onbalans_data(f'{file_path}/settled_imbalance_2022.csv')\n",
        "df_onbalans2023 = onbalans_data(f'{file_path}/settled_imbalance_2023.csv')\n",
        "df_onbalans2024 = onbalans_data(f'{file_path}/settled_imbalance_2024.csv')\n",
        "\n",
        "df_onbalans = pd.concat([df_onbalans2021, df_onbalans2022, df_onbalans2023, df_onbalans2024], ignore_index=True)\n",
        "\n",
        "df_samen = pd.merge(df_all, df_onbalans, on=['maand', 'DagM', 'ISP', 'jaar'], how='left')\n",
        "# due to leap year in 2024 there are nans in it\n",
        "df_samen.dropna(inplace=True)\n",
        "\n",
        "# save to csv for in the drive\n",
        "df_samen.to_csv(f'{file_path}/all_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz9l6kNNq2uG"
      },
      "outputs": [],
      "source": [
        "#@title Models\n",
        "def build_vanilla(neurons, lr):\n",
        "    \"\"\"\n",
        "    Builds a Vanilla RNN model with arbitrary depth.\n",
        "\n",
        "    Parameters:\n",
        "    - neurons: in a list, one per RNN layer (e.g., [32], [64, 32], etc.)\n",
        "    - lr: learning rate\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    for i, n in enumerate(neurons):\n",
        "        # return_sequences for all layer, instead of last layer\n",
        "        return_seq = i < len(neurons) - 1\n",
        "        model.add(SimpleRNN(n, activation='tanh', return_sequences=return_seq))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer=RMSprop(learning_rate=lr))\n",
        "    return model\n",
        "\n",
        "def build_lstm(neurons, lr):\n",
        "    model = Sequential()\n",
        "\n",
        "    for i, n in enumerate(neurons):\n",
        "        # return_sequences for all layer, instead of last layer\n",
        "        return_seq = i < len(neurons) - 1\n",
        "        model.add(LSTM(n, activation='tanh', return_sequences=return_seq))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=lr))\n",
        "    return model\n",
        "\n",
        "def build_gru(neurons, lr):\n",
        "    model = Sequential()\n",
        "    for i, n in enumerate(neurons):\n",
        "        # return_sequences for all layer, instead of last layer\n",
        "        return_seq = i < len(neurons) - 1\n",
        "        model.add(GRU(n, activation='tanh', return_sequences=return_seq))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    adam = optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "def build_biRNN(neurons, lr):\n",
        "    model = Sequential()\n",
        "    model = Sequential()\n",
        "    for i, n in enumerate(neurons):\n",
        "        # return_sequences for all layer, instead of last layer\n",
        "        return_seq = i < len(neurons) - 1\n",
        "        model.add(Bidirectional(SimpleRNN(n, activation='tanh', return_sequences=return_seq)))\n",
        "\n",
        "    model.add(Dense(1))\n",
        "    adam = optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    return model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}